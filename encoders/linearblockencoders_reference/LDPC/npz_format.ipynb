{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gm_to_generator(gm):\n",
    "    for line_index in np.arange(len(gm)):\n",
    "        if gm[line_index][0] == 'nb_cols':\n",
    "            m = int(gm[line_index][3])\n",
    "        elif gm[line_index][0] == 'nb_rows':\n",
    "            n = int(gm[line_index][3])\n",
    "        elif gm[line_index][0] == 'src_indx':\n",
    "            src_index = np.array(gm[line_index+1], dtype=np.int32)\n",
    "        elif gm[line_index][0] == 'par_indx':\n",
    "            par_index = np.array(gm[line_index+1], dtype=np.int32)\n",
    "        elif gm[line_index][0] == 'nzentries_per_row':\n",
    "            start = line_index\n",
    "            continue\n",
    "\n",
    "    parity_matrix = np.zeros(shape=(n,m), dtype=np.float32)\n",
    "    generator_line = 0\n",
    "\n",
    "    for line_index in np.arange(start=start+1, stop=len(gm)):\n",
    "        for a in gm[line_index]:\n",
    "            parity_matrix[generator_line][int(a)] = 1\n",
    "        generator_line += 1\n",
    "    \n",
    "    k = len(src_index)\n",
    "    generator_matrix = np.zeros((m,k), dtype=np.float32)\n",
    "\n",
    "    basis = np.zeros(k, dtype=np.float32)\n",
    "    basis[0] = 1.\n",
    "\n",
    "    for basis_index in np.arange(k):\n",
    "        src_word = np.roll(basis, basis_index)\n",
    "        generator_matrix[src_index, basis_index] = src_word\n",
    "        \n",
    "    for line_index in np.arange(n):\n",
    "        res = np.matmul(parity_matrix[line_index,:], generator_matrix) % 2\n",
    "        generator_matrix[par_index[line_index], :] = res\n",
    "\n",
    "    generator_matrix = np.transpose(generator_matrix)\n",
    "\n",
    "    return (generator_matrix, src_index, par_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_alist_path = os.path.join('./','ml-decoding-gnbp_LA_reference')\n",
    "alist_file_name = 'n64_k18_m46_dv2-4_dc3-4.alist'\n",
    "\n",
    "alist_path = os.path.join(main_alist_path, alist_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 64\n",
      "k: 18\n",
      "n-k: 46\n"
     ]
    }
   ],
   "source": [
    "with open(alist_path, \"r\") as myfile:\n",
    "    data = myfile.readlines()\n",
    "    a_list = [[int(x) for x in elt.replace(' \\n','').replace(' ',',').split(',')] for elt in data]\n",
    "    \n",
    "n = int(a_list[0][0])\n",
    "k = int(n - a_list[0][1])\n",
    "n_k = int(a_list[0][1])\n",
    "\n",
    "print(f'n: {n}')\n",
    "print(f'k: {k}')\n",
    "print(f'n-k: {n_k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_idx = a_list[4:4+n]\n",
    "check_idx = a_list[4+n:4+n+1+n_k]\n",
    "\n",
    "parity_check_matrix = np.zeros([n,n_k])\n",
    "\n",
    "for i in range(n):\n",
    "    for idx in var_idx[i]:\n",
    "        if idx != 0:\n",
    "            parity_check_matrix[i][(idx-1)] = 1\n",
    "\n",
    "H_non_systematic = parity_check_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maths import GaussJordanGF2, LegacyGaussJordanGF2\n",
    "\n",
    "gj = GaussJordanGF2(n=n, k=k, output_all=True, trainable=False)\n",
    "# gj = LegacyGaussJordanGF2(n=n, k=k, output_all=True, trainable=False)\n",
    "\n",
    "G_non_systematic, G_systematic, H_systematic, source_index, parity_index = gj(H_non_systematic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syndrom systematic = 0.0\n",
      "Syndrom non systematic = 0.0\n"
     ]
    }
   ],
   "source": [
    "syndrom_systematic = tf.reduce_sum(tf.matmul(G_systematic, H_systematic, transpose_b=True) % 2)\n",
    "syndrom_non_systematic = tf.reduce_sum(tf.matmul(G_non_systematic, H_non_systematic, transpose_b=True) % 2)\n",
    "\n",
    "print(f'Syndrom systematic = {syndrom_systematic}')\n",
    "print(f'Syndrom non systematic = {syndrom_non_systematic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source data errors (systematic): 0.0\n",
      "Source data errors (non systematic): 0.0\n",
      "Differences between G_non_systematic and G_systematic = 0.0\n"
     ]
    }
   ],
   "source": [
    "from encoders import LinearBlockEncoder\n",
    "\n",
    "data = tf.eye(num_rows=k, dtype=tf.float32)\n",
    "\n",
    "encoder = LinearBlockEncoder(n=n, k=k, trainable=False)\n",
    "encoder.w_generator_matrix = G_systematic\n",
    "\n",
    "codeword = encoder(data)\n",
    "source_data = tf.gather(codeword, indices=tf.range(k, dtype=tf.int32), axis=1)\n",
    "print(f'Source data errors (systematic): {tf.reduce_sum(tf.abs(source_data - data))}')\n",
    "\n",
    "encoder.w_generator_matrix = G_non_systematic\n",
    "\n",
    "codeword = encoder(data)\n",
    "source_data = tf.gather(codeword, indices=source_index, axis=1)\n",
    "print(f'Source data errors (non systematic): {tf.reduce_sum(tf.abs(source_data - data))}')\n",
    "\n",
    "print(f'Differences between G_non_systematic and G_systematic = {tf.reduce_sum(tf.abs(G_non_systematic - G_systematic))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_non_systematic errors = 0.0\n",
      "G_systematic errors = 0.0\n",
      "Source index errors = 0\n",
      "Parity index errors = 722\n",
      "Syndrom systematic = 0.0\n",
      "Syndrom non systematic = 0.0\n"
     ]
    }
   ],
   "source": [
    "main_gm_path = os.path.join('./','ml-decoding-gnbp_LA_reference')\n",
    "gm_file_name = 'n64_k18_m46_dv2-4_dc3-4.gm'\n",
    "\n",
    "gm_path = os.path.join(main_gm_path, gm_file_name)\n",
    "\n",
    "with open(gm_path, \"r\") as myfile:\n",
    "    data = myfile.readlines()\n",
    "    gm = [[x for x in elt.replace(' \\n','').replace('\\n','').replace(' ',',').split(',')] for elt in data]\n",
    "\n",
    "generator_matrix, src_index, par_index = gm_to_generator(gm)\n",
    "\n",
    "print(f'G_non_systematic errors = {tf.reduce_sum(tf.abs(G_non_systematic - generator_matrix))}')\n",
    "print(f'G_systematic errors = {tf.reduce_sum(tf.abs(G_systematic - generator_matrix))}')\n",
    "print(f'Source index errors = {tf.reduce_sum(tf.abs(source_index - src_index))}')\n",
    "print(f'Parity index errors = {tf.reduce_sum(tf.abs(parity_index - par_index))}')\n",
    "\n",
    "syndrom_systematic = tf.reduce_sum(tf.matmul(generator_matrix, H_systematic, transpose_b=True) % 2)\n",
    "syndrom_non_systematic = tf.reduce_sum(tf.matmul(generator_matrix, H_non_systematic, transpose_b=True) % 2)\n",
    "\n",
    "print(f'Syndrom systematic = {syndrom_systematic}')\n",
    "print(f'Syndrom non systematic = {syndrom_non_systematic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_save_path = os.path.join('./', 'reference')\n",
    "npz_file_name = 'n64_k18_m46_dv2-4_dc3-4.npz'\n",
    "\n",
    "npz_path = os.path.join(main_save_path, npz_file_name)\n",
    "np.savez(npz_path, G_non_systematic=G_non_systematic, G_systematic=G_systematic, H_systematic=H_systematic, H_non_systematic=H_non_systematic, src_index=source_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [18,64] vs. [46,64] [Op:Sub]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5139/1250353308.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgenerator_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpar_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgm_to_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'G_non_systematic errors = {tf.reduce_sum(tf.abs(G_non_systematic - generator_matrix))}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'G_systematic errors = {tf.reduce_sum(tf.abs(G_systematic - generator_matrix))}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Source index errors = {tf.reduce_sum(tf.abs(source_index - src_index))}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mld/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mld/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mld/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36msubtract\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mld/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m  10642\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10643\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10644\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10645\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10646\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mld/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mld/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [18,64] vs. [46,64] [Op:Sub]"
     ]
    }
   ],
   "source": [
    "main_gm_path = os.path.join('./','ml-decoding-gnbp_LA_reference')\n",
    "gm_file_name = 'n64_k46_m18_dv2-3_dc9-10.gm'\n",
    "\n",
    "gm_path = os.path.join(main_gm_path, gm_file_name)\n",
    "\n",
    "with open(gm_path, \"r\") as myfile:\n",
    "    data = myfile.readlines()\n",
    "    gm = [[x for x in elt.replace(' \\n','').replace('\\n','').replace(' ',',').split(',')] for elt in data]\n",
    "\n",
    "generator_matrix, src_index, par_index = gm_to_generator(gm)\n",
    "\n",
    "print(f'G_non_systematic errors = {tf.reduce_sum(tf.abs(G_non_systematic - generator_matrix))}')\n",
    "print(f'G_systematic errors = {tf.reduce_sum(tf.abs(G_systematic - generator_matrix))}')\n",
    "print(f'Source index errors = {tf.reduce_sum(tf.abs(source_index - src_index))}')\n",
    "print(f'Parity index errors = {tf.reduce_sum(tf.abs(parity_index - par_index))}')\n",
    "\n",
    "syndrom_systematic = tf.reduce_sum(tf.matmul(generator_matrix, H_systematic, transpose_b=True) % 2)\n",
    "syndrom_non_systematic = tf.reduce_sum(tf.matmul(generator_matrix, H_non_systematic, transpose_b=True) % 2)\n",
    "\n",
    "print(f'Syndrom systematic = {syndrom_systematic}')\n",
    "print(f'Syndrom non systematic = {syndrom_non_systematic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_non_systematic errors = 311.0\n",
      "H_systematic errors = 400.0\n",
      "G_non_systematic errors = 868.0\n",
      "G_systematic errors = 400.0\n",
      "Source index: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n",
      "Parity index: [46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n"
     ]
    }
   ],
   "source": [
    "# code_matrices = np.load(f'reference/BCH_{n}_{k}.npz')ml-decoding-gnbp_LA_reference\n",
    "code_matrices = np.load(f'ml-decoding-gnbp_LA_reference/n64_k46_m18_dv3_dc10-11.npz')\n",
    "\n",
    "try:\n",
    "    reference_systematic_generator_matrix = tf.convert_to_tensor(code_matrices['G'], dtype=tf.float32)\n",
    "    reference_non_systematic_generator_matrix = tf.convert_to_tensor(code_matrices['G'], dtype=tf.float32)\n",
    "except:\n",
    "    reference_systematic_generator_matrix = tf.convert_to_tensor(code_matrices['G_systematic'], dtype=tf.float32)\n",
    "    reference_non_systematic_generator_matrix = tf.convert_to_tensor(code_matrices['G_non_systematic'], dtype=tf.float32)\n",
    "reference_systematic_paritycheck_matrix = tf.convert_to_tensor(code_matrices['H_systematic'], dtype=tf.float32)\n",
    "reference_nonsystematic_paritycheck_matrix = tf.convert_to_tensor(code_matrices['H_non_systematic'], dtype=tf.float32)\n",
    "\n",
    "print(f'H_non_systematic errors = {tf.reduce_sum(tf.abs(H_non_systematic - reference_nonsystematic_paritycheck_matrix))}')\n",
    "print(f'H_systematic errors = {tf.reduce_sum(tf.abs(H_systematic - reference_systematic_paritycheck_matrix))}')\n",
    "print(f'G_non_systematic errors = {tf.reduce_sum(tf.abs(G_non_systematic - reference_non_systematic_generator_matrix))}')\n",
    "print(f'G_systematic errors = {tf.reduce_sum(tf.abs(G_systematic - reference_systematic_generator_matrix))}')\n",
    "print(f'Source index: {source_index}')\n",
    "print(f'Parity index: {parity_index}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9d82509e0ebe3250aa9eee769ff1abd7154ecfb0bc807a4066097fcb0cc991a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('mld': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
